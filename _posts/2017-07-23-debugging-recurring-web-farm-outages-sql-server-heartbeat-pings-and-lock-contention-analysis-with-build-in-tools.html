---
layout: post
title: "Debugging recurring web farm outages: SQL Server heartbeat pings and lock contention analysis with build-in tools"
date: 2017-07-23 12:00 UTC
---

<div id="post">

<p>
Part 1: <a href="/blog/2017/07/16/debugging-recurring-web-farm-outages-establishing-context-with-http-heartbeat-pings">Establishing context with HTTP heartbeat pings</a><br>
Part 2: <a href="/blog/2017/07/17/debugging-recurring-web-farm-outages-analyzing-windows-event-log-iis-log-sharepoint-log-with-powershell">Analyzing Windows Event Log, IIS log, and SharePoint log with PowerShell</a><br>
Part 3: <a href="/blog/2017/07/18/debugging-recurring-web-farm-outages-collecting-and-analyzing-the-memory-dump-with-debugdiag">Collecting and analyzing a memory dump with DebugDiag</a><br>
Part 4: <a href="/blog/2017/07/19/debugging-recurring-web-farm-outages-analyzing-the-memory-dump-with-windbg">Analyzing the memory dump with WinDbg</a><br>
Part 5: SQL Server heartbeat pings and lock contention analysis with build-in tools
</p>

<p>In
the <a href="/blog/2017/07/19/debugging-recurring-web-farm-outages-analyzing-the-memory-dump-with-windbg">previous</a>
post, we used WinDbg to debug OLE DB used by native code SharePoint to
communicate with SQL Server. From OLE DB we managed to extract the SQL
statement on which worker threads block. Turns out they all block on a
call to proc_AddAuditEntry, a stored procedure responsible for writing
audit log entries the content database. As such, when audit logging is
enabled for a site collection, this procedure records the request
before actual content is fetched.</p>

<p>In this post we develop a SQL Server heartbeat tool to measure
general database availability. Then we use build-in SQL Server
monitoring tools to determine what causes proc_AddAuditEntry to
block.</p>

<h4>Collecting SQL Server heartbeats</h4>

<p>Much akin to
the <a href="/blog/2017/07/16/debugging-recurring-web-farm-outages-establishing-context-with-http-heartbeat-pings">HTTP
heartbeat ping tool</a>, in order to measure availability, we want to
issue periodic requests to SQL Server. That way we can tell if the
issue is local to proc_AddAuditEntry and if the database (or server)
is experiencing symptoms of instability.</p>

<p>The HTTP heartbeat and SQL Server heartbeat tools are structurally
equivalent. The latter connects to SQL server and executes a fixed
query. As native code SharePoint connects using OLE DB, the tool
executes the same query using both ADO.NET and OLE DB, just in case
there's an issue only facing OLE DB:</p>

<pre class="prettyprint lang-cs" style="overflow: auto; word-wrap: normal; white-space: pre;">
namespace SQLServerHeartbeat {
    class Program {
        static void Main(string[] args) {
            var run = 0;
            while (true) {
                var ole = "";
                var ado = "";
                Console.Write($"{++run} {DateTime.Now} ");

                using (var con = new OleDbConnection("Provider=sqloledb;Data Source=sql.acme.dk,1433;Initial Catalog=SP_Intranet_Content_01; Integrated Security=SSPI;"))
                using (var cmd = new OleDbCommand("select count(*) from AllDocs (nolock)", con)) {
                    try {
                        con.Open();
                        var res = (int)cmd.ExecuteScalar();
                        ole = res == 0 ? "Empty" : "OK";
                    } catch (Exception e) {
                        Console.WriteLine(e.Message);
                    }
                }

                using (var con = new SqlConnection("Server=tcp:sql.acme.dk,1433;Database=SP_Intranet_Content_01; Integrated Security=SSPI;Encrypt=True;TrustServerCertificate=True;Connection Timeout=30;"))
                using (var cmd = new SqlCommand("select count(*) from AllDocs (nolock)", con)) {
                    try {
                        con.Open();
                        var res = (int)cmd.ExecuteScalar();
                        ado = res == 0 ? "Empty" : "OK";
                    } catch (Exception e) {
                        Console.WriteLine(e.Message);
                    }
                }

                Console.WriteLine($"{ole} {ado}");
                Thread.Sleep(int.Parse(args[0]) * 1000);
            }
        }
    }
}
</pre>

<p>Once setup to run on the reference laptop, the SQL Server, and Web
front-end Server 2, we awaited the HTTP heartbeat tool to report
SharePoint as down. That happened between July 20, 22:47:04 and July
21, 00:18:06. SQL Server heartbeat kept going for entire duration,
though. This confirms an earlier analysis of SharePoint 12 hive log
files recording database activity when HTTP-based SharePoint is
unavailable.</p>

<p>The finding of SharePoint down and SQL Server up points in the
direction of contention around writes to the audit log. What
proc_AddAuditEntry does is technically straightforward. With the
exception of DocLocation, the procedure inserts its arguments into the
AuditData table:</p>

<pre style="overflow: auto; word-wrap: normal; white-space: pre;">
INSERT INTO AuditData (SiteId, ItemId, ItemType, UserId, MachineName, MachineIp, 
                       DocLocation, LocationType, <font color="red">Occurred</font>, Event, 
                       EventName, EventSource, SourceName, EventData)
       VALUES (@SiteId, @ItemId, @ItemType, @UserId, @MachineName, @MachineIp, 
               @Location, @LocationType, <font color="red">@Occurred</font>, @Event, 
               @EventName, @EventSource, @SourceName, @EventData)
</pre>

<p>The audit log has the potential
for <a href="https://blogs.msdn.microsoft.com/subhajitc/2009/05/20/tip-the-untold-story-of-audit-logs-in-sharepoint">high-frequency
inserts and rapid growth</a>. Especially on an intranet which has had
full auditing enabled since 2010 and where the audit log has never
been trimmed. Here the AuditData table itself holds a very large
amount of data. Add to that the storage required for its two indices:
AuditData_OnSiteOccurredEvent and AuditData_OnSiteItem:</p>

<pre style="overflow: auto; word-wrap: normal; white-space: pre;">
<font color="green">sp_spaceused AuditData</font>

name       rows         reserved        data             index_size     unused
AuditData  <font color="red">500,797,831</font>  179,610,816 KB  <font color="red">144,268,664 KB</font>   34,772,344 KB  569,808 KB
</pre>

<p>To better get a feeling for the normal activity pattern around the
AuditData table, we summarize hourly inserts across two days. Keep in
mind that the Occurred field used for filtering is in UTC, i.e., two
hours behind local time:</p>

<pre style="overflow: auto; word-wrap: normal; white-space: pre;">
<font color="green">select count(*) 
from AuditData (nolock)
where Occurred >= '2017-07-21 00:00' and 
      Occurred < '2017-07-21 01:00'</font>
  
July 20                       July 21  
00-01:    914  12-13: 26.225  00-01:  1.968  12-13: 14.739
01-02:  1.158  13-14: 22.483  01-02:  2.004  13-14:  4.642
02-03:  1.338  14-15:  8.773  02-03:  2.376  14-15:  2.731
03-04: 11.849  15-16:  2.422  03-04: 14.064  15-16:  1.485
04-05:  4.925  16-17:  2.629  04-05: 12.382  16-17:  1.473
05-06: 16.067  17-18:  3.299  05-06: 21.108  17-18:  1.124
06-07: 17.375  18-19:  2.676  06-07: 28.543  18-19:  1.108
07-08: 16.610  19-20:  3.035  07-08: 12.564  19-20:  1.289
08-09: 19.646  20-21:  2.813  08-09: 20.205  20-21:  1.367
09-10: 16.179  <font color="red">21-22:     90</font>  09-10: 14.243  <font color="red">21-22:     36</font>
10-11: 15.621  22-23:  5.605  10-11: 13.648  22-23:  4.413
11-12: 19.401  23-00:  2.100  11-12: 11.324  23-00:  1.349 
</pre>

<p>For the whole hour of 23-00 local time of each day, we know that
SharePoint is down, translating to between 21 and 22 UTC. Clearly, a
correlation exists between inserts on AuditData and downtimes.</p>

<h4>Investigating lock contention on AuditData</h4>

<p>The
most <a href="https://blog.wsol.com/sql-server-locks-blocked-processes-and-two-easy-ways-to-find-them">straightforward
way to view locks in MS SQL Server</a> is during application
downtime. Here the Activity Monitor, the Log File View, the sp_who2
stored procedure, and the dm_tran_locks
<a href="https://docs.microsoft.com/en-us/sql/relational-databases/system-dynamic-management-views/system-dynamic-management-views">dynamic
management view</a> are valuable tools for inspecting lock
behavior. The table below shows what we can learn from sp_who2 by
executing it shortly after SharePoint goes offline. Here we're looking
at SharePoint downtime between July 21, 22:47:38 and July 22,
00:20:43:</p>

<pre style="overflow: auto; word-wrap: normal; white-space: pre;">
<font color="green">sp_who2 'active'</font>

Currated output:
SPID  Status     HostName   BlkBy   DBName                  Command      LastBatch       ProgramName
 <font color="red">906</font>  RUNNABLE   WFE4               SP_Intranet_Content_01  ALTER INDEX  07/21 22:45:38  .Net SqlClient Data Provider
<font color="red">1011</font>  SUSPENDED  ADMIN       <font color="red"> 906</font>   SP_Intranet_Content_01  INSERT       07/21 22:47:33  Internet Information Services
 348  SUSPENDED  WFE1        <font color="red">1011</font>   SP_Intranet_Content_01  INSERT       07/21 22:47:38  Internet Information Services
 353  SUSPENDED  WFE1        <font color="red">1011</font>   SP_Intranet_Content_01  INSERT       07/21 22:47:43  Internet Information Services
 197  SUSPENDED  WFE2        <font color="red">1011</font>   SP_Intranet_Content_01  INSERT       07/21 22:47:43  Internet Information Services
...
</pre>

<p>At 22:45:38 an alter index command comes in from Web front-end
server 4. It causes the following insert to blocks, indicated by SPID
906 in the BlkBy column. Later inserts block on the first insert, and
inserts keep queuing up. Starting 22:56:22 and ending 23:35:02, on
nine occasions, according to the SQL Server Log File Viewer, SPID 906
was killed by the management process. When it first happened, sp_who2
changed to report SPID 906 as follows:</p>

<pre style="overflow: auto; word-wrap: normal; white-space: pre;">
SPID  Status    HostName   BlkBy  DBName                  Command          LastBatch       ProgramName
<font color="red">906</font>   ROLLBACK  WFE4              SP_Intranet_Content_01  <font color="red">KILLED/ROLLBACK</font>  07/21 22:45:38  .Net SqlClient Data Provider
</pre>

<p>While rollback is in progress, inserts remain blocked on SPID
906. Once the rollback is complete, and the lock on alter index is
released, queued inserts are retroactively written to AuditData. That
explains why even though SharePoint is down, (some) audit log still
show up.</p>

<p>From the output of sp_who2 alone we cannot be certain that what
we're looking at are operations against AuditData. To confirm, we need
to query dm_tran_locks, holding details about locks being held and
requested:

<pre style="overflow: auto; word-wrap: normal; white-space: pre;">
<font color="green">select * from sys.dm_tran_locks</font>

Currated output:
request_session_id  resource_subtype  resource_associated_entity_id  request_mode  request_type  request_status
 906                INDEX_OPERATION   <font color="red">1826105546</font>                     Sch-M         LOCK          GRANT
1011                                  <font color="red">1826105546</font>                     IX            LOCK          WAIT
 348                                  <font color="red">1826105546</font>                     IX            LOCK          WAIT
 353                                  <font color="red">1826105546</font>                     IX            LOCK          WAIT
 197                                  <font color="red">1826105546</font>                     IX            LOCK          WAIT

<font color="green">select * from sys.objects where object_id = <font color="red">1826105546</font></font>

Currated output:
name       object_id   type  type_desc   create_date
AuditData  <font color="red">1826105546</font>  U     USER_TABLE  2010-05-12 15:45:05.160
</pre>

<p>The dm_tran_locks output confirms that SPID 906 is granted a lock
because of an index_operation and that other requests are waiting for
the lock to be released. The request_mode
(<a href="https://technet.microsoft.com/en-us/library/ms175519(v=sql.105).aspx">request
lock mode</a> in full) of Sch-M is short for schema modification. A
lock of type Sch-M prevents concurrent access to the table, meaning
that Sch-M blocks inserts.</p>

<p>Furthermore, a few times during the downtime and later at 00:24:34
and 00:52:46, the Log File Viewer displays messages indicating that
the I/O subsystem is overloaded, likely due to the large sizes of the
table and its indices:</p>

<pre style="overflow: auto; word-wrap: normal; white-space: pre;">
SQL Server has encountered <font color="red">1699 occurrence(s) of I/O requests taking
longer than 15 seconds to complete</font> on file
[D:\MSSQL\DATA\SP_Intranet_Content_01.mdf:MSSQL_DBCC116] in database
[SP_Intranet_Content_01] (116).  The OS file handle is
0x0000000000000A24.  The offset of the latest long I/O is:
0x00003781ada000
</pre>

<h4>Investigating SharePoint timer jobs on WFE4</h4>

<p>Let's have a look at WFE4, the originating host. With the client
listed as ".Net SqlClient Data Provider", it's probably one of
SharePoint's timer jobs. In Central Administration, under Timer Job
Status, one job stands out. Below is what its status looks like during
the downtime. It's a bit odd that on the following day of July 22, the
Timer Job status page lists that very same job as succeeded and
progress being 100%. Perhaps the timer job attempts a number of
re-runs:</p>

<pre style="overflow: auto; word-wrap: normal; white-space: pre;">
Job Title            Server        Status  Progress  Started
Database Statistics  WFE4     Initialized  0%        <font color="red">7/21/2017 10:45 PM</font>
</pre>

<p>The <a href="https://technet.microsoft.com/en-us/library/cc678870(v=office.12).aspx">purpose
of the Database Statistics job</a> is to
<a href="http://www.sqlmvp.org/use-update-statistics-command-in-ms-sql-server">update
query statistics</a> for main tables inside the Intranet content
database. On SQL Server 2008 Enterprise Edition, which the farm is
running, the job rebuilds <i>most</i> (for some unknown definition of
most) indices online. The Database statistics timer job works by
calling the proc_UpdateStatistics stored procedure which, according to
a support article
is <a href="https://support.microsoft.com/en-us/help/3103194/outdated-database-statistics-decrease-sharepoint-server-performance--c">
unreliable when run in parallel with a database backup</a>. The stored
procedure contains lines such as the following for each main
table:</p>

<pre style="overflow: auto; word-wrap: normal; white-space: pre;">
update statistics AuditData with resample
</pre>

<p>The support article mentions the operational status codes logged by
Database Statistics to SharePoint's 12 hive log. All servers in farm
are configured to store log files under E:\SharePoint\Logs. Yet, WFE4
stores no 12 hive log files more recent than February 19, 2015 at that
location. That issue is for another time to investigate.</p>

<h4>Conclusion</h4>

<p>Perhaps unsurprisingly, AuditData needs trimming. The stsadm
command provides
the <a href="https://technet.microsoft.com/en-us/library/cc706879.aspx">Trimauditlog</a>
operation for that purpose, but it must be used incrementally. The
operation of trimming acquires locks which for longer runs take down
SharePoint. Only for SharePoint 2010 and up, does Central
Administration allow for the specification of the number of days to
retain audit log entries and a location to store entries into prior to
trimming.</p>

</div>
