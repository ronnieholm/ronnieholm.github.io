---
layout: post
title: "Informally speed testing SharePoint Online"
date: 2015-03-28 12:00 UTC
tags: [C#]
---
<div id="post">

<p>In order to systematically identify potential bottlenecks between a
computer on a local network and SharePoint Online, we modify the
console application for
<a href="/blog/2015/03/13/informally-speed-testing-azure-blob-storage">benchmarking
Azure blob storage</a> to work with SharePoint document libraries.</p>

<h2>Setup</h2>

<p>Let's start with common code for initializing the SharePoint
context, a utility method for timing code blocks, and general skeleton
code:</p>

<pre class="prettyprint lang-cs">
// 1. Reference Microsoft.SharePoint.Client.dll and Microsoft.SharePoint.Client.Runtime.dll
//    from C:\Program Files\Common Files\Microsoft Shared\Web Server Extensions\16\ISAPI or
//    download from https://github.com/OfficeDev/PnP/tree/master/Assemblies/16
// 2. Build as 64 bit assembly to avoid OutOfMemoryExceptions

using System;
using System.Diagnostics;
using System.IO;
using System.Linq;
using System.Security;
using System.Threading;
using Microsoft.SharePoint.Client;
using SPOFile = Microsoft.SharePoint.Client.File;

namespace SharePointOnlineSpeedTest {
    class Program {       
        const int Megabyte = 1024 * 1024;
        const int Megabit = 1000 * 1000;

        static ClientContext SetupContext(Uri siteCollection) {
            var user = "rh@bugfree.onmicrosoft.com";
            var password = "password";
            var securePassword = new SecureString();
            password.ToCharArray().ToList().ForEach(securePassword.AppendChar);
            var credentials = new SharePointOnlineCredentials(user, securePassword);
            return new ClientContext(siteCollection) { Credentials = credentials };
        }

        static double Time(Action toMeasure) {
            var w = new Stopwatch();
            w.Start();
            toMeasure();
            w.Stop();
            return w.ElapsedMilliseconds / 1000.0;
        }

        static void Main(string[] args) {
            // code below goes here
        }
    }   
}
</pre>

<p>The SharePoint client side object model offers (at least) two ways
of uploading files to a document library. One way is using
the <a href="https://msdn.microsoft.com/en-us/library/microsoft.sharepoint.client.filecreationinformation.aspx">FileCreationInformation</a>
class like so:

<pre class="prettyprint lang-cs">
// take 1
using (var ctx = SetupContext(new Uri("https://bugfree.sharepoint.com/sites/test"))) {
    var library = ctx.Web.Lists.GetByTitle("speedtest");
    var newFile =
        library.RootFolder.Files.Add(
            new FileCreationInformation {
                Url = "randombits",
                Content = System.IO.File.ReadAllBytes(@"c:\users\rh\desktop\randombits")
            });
    ctx.Load(newFile);
    ctx.ExecuteQuery();
}
</pre>

<p>The above code works well for file sizes less than two megabytes,
but
otherwise throws a <a href="http://stackoverflow.com/questions/20076871/sharepoint-2013-client-object-model-file-larger-than-2-mb-exception">request message too long exception</a>. As we require a file size larger than two megabytes
to reliably gauge upload and download speeds, we turn to the second
option,
using <a href="https://msdn.microsoft.com/en-us/library/ee538285.aspx">SaveBinaryDirect
method</a> and
the <a href="http://en.wikipedia.org/wiki/WebDAV">WebDAV
protocol</a>.</p>

<pre class="prettyprint lang-cs">
// take 2
var destination = new Uri(args[0]);
var sizeInMegabytes = int.Parse(args[1]);
var contentLength = sizeInMegabytes * Megabyte;
var randomizedContent = new byte[contentLength];
new Random().NextBytes(randomizedContent);

using (var ctx = SetupContext(destination)) {
    // internally the context uses HttpWebRequest to upload and download files.
    // Thus, uploading or downloading large files, we may experience
    //   Unhandled Exception: System.Net.WebException: The operation has timed out
    // unless we don't change the default timeout period of 180 seconds.
    ctx.RequestTimeout = Timeout.Infinite;

    var uploadTime = Time(() => {
        using (var ms = new MemoryStream(randomizedContent)) {
            SPOFile.SaveBinaryDirect(ctx, destination.LocalPath, ms, true);
        }
    });

    var downloadTime = Time(() => {
        var fileInformation = SPOFile.OpenBinaryDirect(ctx, destination.LocalPath);
        using (var sr = new StreamReader(fileInformation.Stream)) { 
            sr.ReadToEnd(); 
        }
    });

    Console.WriteLine(
        "{0} MB uploaded in {1:0.0} seconds at {2:0.0} Mbit/s\r\n" +
        "{0} MB downloaded in {3:0.0} seconds at {4:0.0} Mbit/s",
        sizeInMegabytes, uploadTime, contentLength / uploadTime * 8 / Megabit,
        downloadTime, contentLength / downloadTime * 8 / Megabit);
}
</pre>

<h2>Execution</h2>

<p>Running the speed test application on a Windows 2012 Azure virtual machine, here's an average result:</p>

<pre>
%> ./SharePointOnlineSpeedTest.exe https://bugfree.sharepoint.com/sites/test/speedtest/testfile 1024
1024 MB uploaded in 280.9 seconds at 30.6 Mbit/s
1024 MB downloaded in 95.6 seconds at 89.8 Mbit/s
</pre>

<p>According
to <a href="https://support.office.com/en-au/article/SharePoint-Online-software-boundaries-and-limits-8f34ff47-b749-408b-abc0-b605e1f6d498">software
boundaries and limits for SharePoint Online</a>, the file attachment
size limit is 250MB and file upload limit is 2GB per file.</p>

<h2>Conclusion</h2>

<p>Uploading and downloading a document of one gigabyte in size is
surprisingly fast, considering that SharePoint must store the file in
an SQL Server content database (as opposed to blob storage build to
handle large files). In terms of bandwidth, to some extend we could
use SharePoint Online document libraries as an alternative to Azure
blob storage. But SharePoint not being transactional will likely cause
issues down the road.</p>

</div>
