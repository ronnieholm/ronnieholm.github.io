---
layout: post
title: "Recursive descent parsing of mathematical expressions with C#"
date: 2018-12-23 12:00 UTC
---

<div id="post">

<p><a href="/blog/2015/08/05/lexing-and-parsing-mathematical-expressions-with-fsharp">Part 1: Lexing and parsing mathematical expressions with F#</a><br>
<a href="/blog/2015/08/14/evaluating-mathematical-expressions-with-shunting-yard-and-fsharp">Part 2: Evaluating mathematical expressions with Shunting Yard and F#</a><br>
  Part 3: Recursive descent parsing of mathematical expressions with C#</p>

<p>The commented source code for this post is
available <a href="https://github.com/ronnieholm/ExpressionParsers/tree/master/RecursiveDescentParser.CSharp">here</a>.</p>
  
<p>This post is about how to construct a backtracking lexer and a
combined recursive
descent <a href="https://en.wikipedia.org/wiki/LL_parser">LL(1)</a>
parser and evaluator for mathematical expressions. For arbitrary
precedence and associativity, we could switch to Shunting Yard or Top
Down Operator Precedence algorithms (or to Yacc and family), but the
post shows how it's possible to stay with recursive descent. All
that's required is a very small change to the grammar and parser for
it to support both left and right associative operators. With
recursive descent, the parser and grammar rules follow from each other
-- they're isomorphic -- which leads to easy to understand, easy to
debug, easy to extend parsers.</p>

<h3>Textbook expression grammar</h3>

<p>Below is a starting point
<a href="https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form">BNF
grammar</a> for expressions. We'll evolve it into a more capable
grammar with more precedence levels, support for both left and right
associative operators, and support for integers and floats. That's
what our parser will end up supporting:</p>

<pre>
Expression = Term | Expression "+" Term | Expression "-" Term
Term = Factor | Term "*" Factor | Term "/" Factor 
Factor = Power | Factor "^" Power
Power = Integer | "(" Expression ")"
Integer = Digit | Integer Digit    
Digit = "0" | "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9" 
</pre>

<p>That the parser is LL(1) refers to how it parses the expression,
reading tokens left to right and when a list of tokens match a rule,
it does
a <a href="https://en.wikipedia.org/wiki/Context-free_grammar#Derivations_and_syntax_trees">leftmost
derivations</a> of the tokens, i.e., produces a result, such as adding
two numbers. Leftmost derivations corresponds to left associativity so
for an operator like power we must somehow reverse it. The number one
refers to crafting rules in such a way that looking at most one token
ahead, without consuming it, the parser can unambiguously decide on
one rule among many to apply. Organizing these rules from lowest to
highest precedence, enabling precedence climbing and support for
precedence and associativity (for the above grammar, if we flip the
order, we'd go up, or climb the rules, with higher precedence
operators).</p>

<p>Rules are typically named after the domain described by grammar; in
this
case <a href="https://study.com/academy/lesson/parts-of-an-expression-terms-factors-coefficients.html">algebra</a>. Here
terms are the operands in an expression involving addition or
subtraction and factors the operands in an expression involving
multiplication or division. It's convention, and might as well have
ben <code>Addition</code> and <code>Multiplication</code>.</p>

<p>The lexer operates at the character level, grouping characters into
tokens, and would typically implement the <code>Integer</code>
and <code>Digit</code> rules. When we talk about a single token
lookahead, it refers to the operation of the parser and not the
lexer. The lexer may look any number of characters ahead. In fact,
that's a common reason for separating lexing and parsing, simplifying
the parser.</p>

<h3>Adjusting grammar for off-by-one naming</h3>

<p>In the grammar above, rules appear off-by-one:
<code>Expression</code> is about addition and subtraction,
<code>Term</code> about multiplication and division, and so on. If
instead we rewrite, or expand, the first rule into two, we end up with
aligned Terms, Factors, and so on. As we've introduced an extra level,
we name the new rule <code>Primary</code>:</p>

<pre>
Expression = Term
Term = Factor | Term "+" Factor | Term "-" Factor
Factor = Power | Factor "*" Power | Factor "/" Power
Power = Primary | Power "^" Primary
Primary = Integer | "(" Expression ")"
</pre>
 
<p>The rewriting is valid because a grammar with rules <code>A =
B</code> and <code>B = C | D</code> describes the same language
as <code>A = B | C | D</code>. Also, replacing rule names
by <code>Rule0</code>, <code>Rule1</code>,
<code>RuleN</code> with N being the rule's precedence level makes no
difference to language it describes.</p>

<p>In the grammar, a rule's self-reference appears on the left, as in
<code>Term "+" Factor</code>. This feature is how it correctly deals
with left associative operators. For right associative operators, the
rule needs rearranging to <code>Primary "^"
Power</code>. Unfortunately, a recursive descent parser cannot work
with left recursion. It causes the parser to enter an infinite loop as
it recurses into itself.</p>

<h3>Eliminating left recursion through EBNF rule rewriting</h3>

<p>That's where
<a href="https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form">EBNF</a>
comes into play by introducing <code>{ x }</code> rule syntax for zero
or more repetitions of <code>x</code>. In a parser repetition is
expressed with a loop rather than left recursion. We're going from
left fold recursion to left fold iteration.</p>

<pre>
Expression = Term
Term = Factor { ("+" | "-") Factor }
Factor = Power { ("*" | "/")  Power }
Power = Primary { "^" Primary }
Primary = Integer | "(" Expression ")"
</pre>

<p><b>Side note</b>: a recursive descent parser has no problem with
right recursive rules. Instead of substituting left recursion with
iterations, we could rewrite the grammar as all right recursive. The
parser could apply a transformation on the left associative operators
(or
the <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract
Syntax Tree</a> (AST) nodes, depending on the parser's output). While
it would work, it's simpler to eliminating left recursion.</p>

<p>We're extending the grammar to include unary minus and float
support, and also make use of EBNF character groups
and <a href="https://en.wikipedia.org/wiki/Kleene_star">Kleene
star</a> syntax. Naming
rules <code>Addition</code>, <code>Multiplication</code>, <code>Power</code>
is short for operators with addition, multiplication, and power-like
precedence:</p>

<pre>
Expression = Addition
Addition = Multiplication ([+-] Multiplication)*
Multiplication = Power ([*/] Power)*
Power = Unary ("^" Power)*
Unary = '-' Unary | Primary
Primary = Integer | Float | "(" Expression ")"
</pre>

<p><b>Side node</b>: lots of languages are LL(1) at the token level
but not the character level. In fact, one reason to separate lexing
and parsing is to allow the parser to be LL(1). For instance, lexing
isn't LL(1) when determining whether a number is an integer or
float. It bookmarks its current input position, and starts scanning
the input until it encounters either a whitespace or a dot. It then
backtracks to the bookmark and calls the appropriate integer or float
lexer method. While inside a number, only looking at the next digit,
the lexer has no way to tell whether the number is an integer or
float.</p>

<h3>From grammar rules to parser</h3>

<p>A two-way mapping exists between the grammar and parser. Each rule
becomes its own Parse method and the inside of each Parse method
follows from that rule's definition as per Wirth's recipe for
translating EBNF into actual code (see Additional references
below). With a breakpoint inside one such method, the call stack shows
the path from <code>Expression</code> to that rule, illustrating the
one-to-one relationship between grammar and recursive descent
parser.</p>

<p>To keep
the <a href="https://github.com/ronnieholm/ExpressionParsers/tree/master/RecursiveDescentParser.CSharp">implementation</a>
focused on lexer and parsing, evaluation happens during
parsing. Instead of each parse method returning an AST node as with
the <a href="https://github.com/ronnieholm/ExpressionParsers/tree/master/ShuntingYardParser.CSharp">Shunting
Yard implementation</a>, they return the actual result of the
computation. Returning AST nodes, and supplementing the implementation
with as AST walking evaluator, is independent of parsing, also
yielding correct results for associativity and precedence.</p>

<p>Below is the trace from parsing an expression. Enter marks an entry
into a parse method (20 in all) and the value of the current
token. Exit includes the return of each Parse method, i.e., what's
passed up the call chain.</p>

<pre>
// Equivalent to 2+(3^(4^0.5)*5)
> 2+3^4^0.5*5
Enter: Parse, Value: 2
    Enter: ParseExpression, Value: 2
        Enter: ParseAddition, Value: 2
            Enter: ParseMultiplication, Value: 2
                Enter: ParsePower, Value: 2
                    Enter: ParseUnary, Value: 2
                        Enter: ParsePrimary, Value: 2
                        Exit: Value: 2
                    Exit: Value: 2
                Exit: Value: 2
            Exit: Value: 2
            Enter: ParseMultiplication, Value: 3
                Enter: ParsePower, Value: 3
                    Enter: ParseUnary, Value: 3
                        Enter: ParsePrimary, Value: 3
                        Exit: Value: 3
                    Exit: Value: 3
                    Enter: ParsePower, Value: 4
                        Enter: ParseUnary, Value: 4
                            Enter: ParsePrimary, Value: 4
                            Exit: Value: 4
                        Exit: Value: 4
                        Enter: ParsePower, Value: 0.5
                            Enter: ParseUnary, Value: 0.5
                                Enter: ParsePrimary, Value: 0.5
                                Exit: Value: 0.5
                            Exit: Value: 0.5
                        Exit: Value: 0.5
                    Exit: Value: 2
                Exit: Value: 9
                Enter: ParsePower, Value: 5
                    Enter: ParseUnary, Value: 5
                        Enter: ParsePrimary, Value: 5
                        Exit: Value: 5
                    Exit: Value: 5
                Exit: Value: 5
            Exit: Value: 45
        Exit: Value: 47
    Exit: Value: 47
Exit: Value: 47
</pre>

<p>With grammar rules mapping one-to-one to Parse methods, it should
be easy to reconstruct the hierarchy looking at input and grammar
alone. The call tree mirrors precedence and associativity.</p>

<h3>Comparing recursive descent, Shunting Yard, and Pratt parsers</h3>

<p>In parsing, recursive descent is the most intuitive and simplest to
implement. It dates back to the 60s, but back then it was impractical
to implement. The call stack was still a novel concept, function calls
were expensive, and memory scarce, leading Dijkstra to develop the
Shunting Yard algorithm. Today, unless we're parsing large programs
with many precedence levels, recursive descent is a good starting
point.</p>

<p>In 1973, Pratt developed the <a href="https://tdop.github.io">Top
Down Operator Precedence parser</a>, later called the Pratt parser. It
improves on the performance of recursive descent and Shunting Yard in
that regardless of precedence level, a Pratt parser requires only a
single parse method call. This makes Pratt parsers efficient for
grammars with many levels of precedence. It's also useful for
languages with support for dynamic operators. A programmer may add new
operators anywhere in the precedence hierarchy and with any
associativity. Recursive descent could support a similar extensible
grammar through replacing or supplementing the fixed rules with a
lookup table.</p>

<p>As an example of a hybrid of a recursive descent parser for
statements and a Pratt parser for expressions, have a look at
the <a href="https://github.com/ronnieholm/MonkeyLang">MonkeyLang</a>
parser.</p>

<h3>Additional references</h3>

<ul>
<li><p>Niklaus
Wirth's <a href="https://www.inf.ethz.ch/personal/wirth/CompilerConstruction/CompilerConstruction1.pdf">Compiler
construction</a>, Chapter 2 through to Section 4.1 (12 pages). With
examples, these pages cover almost everything needed to write a
recursive descent parser for any language.</p></li>

<li><p>Per
Vognsen's <a href="https://www.youtube.com/watch?v=Mx29YQ4zAuM">Programming
an x64 compiler from scratch - part 2"</a>, from 2h30m to 3h28m,
implements a simple expression parser in
C. Also, <a href="https://www.youtube.com/watch?v=0woxSWjWsb8">Bitwise,
Day 2: C Programming & Parsing</a> from 1h00m
and <a href="https://www.youtube.com/watch?v=L4P98pGhpnE">Bitwise, Day
3: More Programming & Parsing</a> from 1h10m to 1h40m are worth a
look, though they have some overlap.</p></li>

<li><p>Bob
Nystrom's <a href="http://craftinginterpreters.com/parsing-expressions.html">Crafting
Interpreters</a>, Chapter 6 details how to modify an expression
grammar to encode precedence levels.</p></li>

<li><p>Eli
Bendersky's <a href="https://eli.thegreenplace.net/2009/03/14/some-problems-of-recursive-descent-parsers">Some problems of recursive descent parsers</a> details how to transform a
right recursive grammar into repetitions and how to handle left and
right associative operators.</p></li>
</ul>

<!--<h3>Summary</h3>

<p></p>-->

</div>
