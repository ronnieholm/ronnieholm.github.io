---
layout: post
title: "Recursive descent parsing of mathematical expressions with C#"
date: 2018-12-23 12:00 UTC
---

<!-- Wirth book gives simple recipe for translating EBNF into actual code -->
<!-- Precedence mirrors the call tree -->
<!-- Create an extensible grammar by setting up a table -->
<!-- Called precedence climbing because it goes through all the precedence levels 
     We going downwards but if flip the order we'd climb upwards -->
<!-- Power one is left right recursive. Could have more right
recursive operators that could call each other like the left recursive
ones -->
<!-- left fold iteration rather than left fold recursion -->

<!-- Using Kleene start and terse notation for character classes, we
     can actually write rules as expr0 = expr1 ([+-] expr1)*-->
<!-- Grammar is isomorphic to code -->
<!-- Grammer is both directly and indrectly recursive. Power calls itself and last rule ends up calling first rule on parenthesis -->
<!-- Dynamic set of operators ... -->

<div id="post">

<p><a href="/blog/2015/08/05/lexing-and-parsing-mathematical-expressions-with-fsharp">Part 1: Lexing and parsing mathematical expressions with F#</a><br>
<a href="/blog/2015/08/14/evaluating-mathematical-expressions-with-shunting-yard-and-fsharp">Part 2: Evaluating mathematical expressions with Shunting Yard and F#</a><br>
  Part 3: Recursive descent parsing of mathematical expressions with C#</p>

<p>The commented source code for this post is
available <a href="https://github.com/ronnieholm/ExpressionParsers/tree/master/RecursiveDescentParser.CSharp">here</a>.</p>
  
<p>This post is about how to construct a backtracking lexer and a
combined recursive
descent <a href="https://en.wikipedia.org/wiki/LL_parser">LL(1)</a>
parser and evaluator for mathematical expressions. For arbitrary
precedence and associativity, we could switch to Shunting Yard or Top
Down Operator Precedence algorithms (or to Yacc and family), but the
post shows how it's possible to stay with recursive descent. All
that's required is a very small change to the grammar and parser for
it to support both left and right associative operators. With
recursive descent, the parser and grammar rules follow from each other
-- they're isomorphic -- which leads to easy to understand, easy to
debug, easy to extend parsers.</p>

<p>That the parser is LL(1) refers to how it parses the expression,
reading tokens left to right and when a list of tokens match a rule,
it does
a <a href="https://en.wikipedia.org/wiki/Context-free_grammar#Derivations_and_syntax_trees">leftmost
derivations</a> of the tokens, i.e., produces a result, such as adding
two numbers. Leftmost derivations corresponds to left associativity so
for operators like unary minus and power we reverse it. The number one
refers to how rules crafted in such a way that looking at most one
token ahead, without consuming it, the parser can unambiguously decide
on one rule among many to apply. Organizing these rules from lowest to
highest precedence, with one recursively calling the next enables
precedence climbing which in turn enables support for conventional
precedence and associativity.</p>

<h3>Textbook expression grammar</h3>

<p>Below is a starting point
<a href="https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form">BNF
grammar</a> for expressions. We'll evolve it into a more capable
grammar with additional precedence levels, support for both left and
right associative operators, and support for integers and
floats. That's what our parser will end up supporting:</p>

<pre>
Expression = Term | Expression "+" Term | Expression "-" Term
Term = Factor | Term "*" Factor | Term "/" Factor 
Factor = Power | Factor "^" Power
Power = Integer | "(" Expression ")"
Integer = Digit | Integer Digit    
Digit = "0" | "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9" 
</pre>

<p>The lexer operates at the character level, grouping characters into
tokens, and would typically implement the <code>Integer</code>
and <code>Digit</code> rules. When we talk about a single token
lookahead, it refers to the operation of the parser and not the
lexer. The lexer may look any number of characters ahead. In fact,
that's a common reason for separating lexing and parsing, simplifying
the parser.</p>

<p>Rules are typically named after the domain described by grammar; in
this
case <a href="https://study.com/academy/lesson/parts-of-an-expression-terms-factors-coefficients.html">algebra</a>. Here
terms are the operands in an expression involving addition or
subtraction and factors the operands in an expression involving
multiplication or division. It's convention, but the rules might as
well be called <code>Addition</code>
and <code>Multiplication</code>.</p>

<h3>Adjusting grammar for off-by-one naming</h3>

<p>In the textbook expression grammar, rules appear off-by-one:
the <code>Expression</code> rule is about addition and subtraction,
the <code>Term</code> rule about multiplication and division, and so
on. If instead we rewrite, or expand, the first rule into two, we end
up with matching Terms, Factors, and so on match. As we introduced an
extra level, we name the last rule <code>Primary</code>:</p>

<pre>
Expression = Term
Term = Factor | Term "+" Factor | Term "-" Factor
Factor = Power | Factor "*" Power | Factor "/" Power
Power = Primary | Power "^" Primary
Primary = Integer | "(" Expression ")"
</pre>
 
<p>In general, a grammar <code>A = B, B = C | D</code> can be
rewritten as <code>A = B | C | D</code>. Both grammars define the same
language.</p>

<p>Replacing rule names by <code>Rule0</code>, <code>Rule1</code>,
<code>RuleN</code>, where N is the precedence level for the rule's
operator(s) makes no difference. Within a grammar, precedence arises
by one rule referencing the next in increasing order of
precedence.</p>

<p>In the grammar above, the rule's self-reference appears on the left
as in
<code>Term = Term "+" Factor</code>. This makes the rule left
recursive and enables to parse left associative operators,
e.g., <code>a - b - c parses as (a - b) - c</code>. Similarly, a right
recursive rule, such as <code>Primary "^" Power</code> is needed to
parse right associative operators. Unfortunately, a recursive descent
parser cannot work with left recursion. It causes the parser enter an
infinite loop as it recurses into itself.</p>

<h3>Eliminating left recursion with EBNF rule rewriting</h3>

<p>That's where
<a href="https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form">EBNF</a>
comes in. It introduces <code>{ x }</code> syntax for zero or more
repetitions, expressed with a loop rather than recursion.</p>

<p><b>Side note</b>: a recursive descent parser has no issue with
right recursive rules. Thus, instead of substituting left recursive
with iterations, we could rewrite the grammar into right recursive
form and applying a transformation on
the <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract
Syntax Tree</a> (AST) nodes for left associative operators. It's
simpler to eliminating left recursion.</p>

<pre>
Expression = Term
Term = Factor { ("+" | "-") Factor }
Factor = Power { ("*" | "/")  Power }
Power = Primary { "^" Primary }
Primary = Integer | "(" Expression ")"
</pre>
    
<p>Favoring readability over compactness, and extending the grammar to
include unary minus and float support, we end up with this final
grammar:</p>

<pre>
Expression = Addition
Addition = Multiplication { ("+" | "-") Multiplication }
Multiplication = Power { ("*" | "/") Power }
Power = Unary { "^" Power }
Unary = '-' Unary | Primary
Primary = Integer | Float | "(" Expression ")"
</pre>

<p>Naming
rules <code>Addition</code>, <code>Multiplication</code>, <code>Power</code>
is short for operators with addition, multiplication, and power-like
precedence.</p>

<p><b>Side node</b>: lots of languages are LL(1) at the token level
but not the character level. In fact, one reason to separate the lexer
and parser is to allow the parser to be LL(1). For instance, lexing a
integer or float, the lexer bookmarks its current position. It then
scans the input until it encounters either a whitespace or a dot,
before it backtracks to the bookmark and calls the appropriate integer
or float lexer method.</p>

<h3>From grammar rules to parser</h3>

<p>Organizing the parser, each rule becomes a corresponding Parse
method. Placing a breakpoint inside one of these methods, the call
stack shows the path from <code>Expression</code> to the current
rule. This is useful in debugging the parser and goes to show the
one-to-one relationship between grammar and recursive descent
parser.</p>

<p>To keep
the <a href="https://github.com/ronnieholm/ExpressionParsers/tree/master/RecursiveDescentParser.CSharp">implementation</a>
focused on parsing, evaluation happens during parsing. Each parse
method could've returned AST nodes as with
the <a href="https://github.com/ronnieholm/ExpressionParsers/tree/master/ShuntingYardParser.CSharp">Shunting
Yard implementation</a> and we could've added an AST tree walking
interpreter. Both solutions work because the evaluation order is
correct for associativity and precedence.</p>

<p>Below is the trace output from parsing an expression. The trace
reflects the parser's call stack with each Enter marking an entry into
a parse method, 20 in all, and the value of the current token. Exit
marks includes what each parse method returns up the call chain to its
caller.</p>

<pre>
// Equivalent to 2+(3^(4^0.5)*5)
> 2+3^4^0.5*5
Enter: Parse, Value: 2
    Enter: ParseExpression, Value: 2
        Enter: ParseAddition, Value: 2
            Enter: ParseMultiplication, Value: 2
                Enter: ParsePower, Value: 2
                    Enter: ParseUnary, Value: 2
                        Enter: ParsePrimary, Value: 2
                        Exit: Value: 2
                    Exit: Value: 2
                Exit: Value: 2
            Exit: Value: 2
            Enter: ParseMultiplication, Value: 3
                Enter: ParsePower, Value: 3
                    Enter: ParseUnary, Value: 3
                        Enter: ParsePrimary, Value: 3
                        Exit: Value: 3
                    Exit: Value: 3
                    Enter: ParsePower, Value: 4
                        Enter: ParseUnary, Value: 4
                            Enter: ParsePrimary, Value: 4
                            Exit: Value: 4
                        Exit: Value: 4
                        Enter: ParsePower, Value: 0.5
                            Enter: ParseUnary, Value: 0.5
                                Enter: ParsePrimary, Value: 0.5
                                Exit: Value: 0.5
                            Exit: Value: 0.5
                        Exit: Value: 0.5
                    Exit: Value: 2
                Exit: Value: 9
                Enter: ParsePower, Value: 5
                    Enter: ParseUnary, Value: 5
                        Enter: ParsePrimary, Value: 5
                        Exit: Value: 5
                    Exit: Value: 5
                Exit: Value: 5
            Exit: Value: 45
        Exit: Value: 47
    Exit: Value: 47
Exit: Value: 47
</pre>

<p>Because grammar rules map one-to-one to parse methods in mechanical
way, following grammar rules by hand, we'd arrive at the same
order.</p>

<h3>Comparing recursive descent, Shunting Yard, and Pratt parsers</h3>

<p>In parsing, the recursive descent approach is the most
intuitive. It dates back to the 60s, but was impractical to
implement. The call stack was still a novel concept, function calls
were expensive, and memory scarce, leading Dijkstra to develop the
Shunting Yard algorithm. On modern hardware, unless we're parsing
large programs with many precedence levels, recursive descent is a
good starting point.</p>

<p>In 1973, Pratt developed the <a href="https://tdop.github.io">Top
Down Operator Precedence parser</a>, later called the Pratt
parser. It's an improvement over recursive descent and Shunting Yard
in that regardless of precedence level, a Pratt parser requires only a
single parse method call. This makes Pratt parsers efficient for
grammars with many levels of precedence. It's also useful for
languages in which the programmer may add new operators anywhere in
the precedence hierarchy and with any associativity. For recursive
descent, we could supplement fixed rules with a lookup table of the
next parse method.</p>

<p>As an example of a hybrid of a recursive descent parser for
statements and a Pratt parser for expressions, take a look at
the <a href="https://github.com/ronnieholm/MonkeyLang">MonkeyLang</a>
parser.</p>

<h3>Additional references</h3>

<ul>
<li><p>Niklaus
Wirth's <a href="https://www.inf.ethz.ch/personal/wirth/CompilerConstruction/CompilerConstruction1.pdf">Compiler
construction</a>, Chapter 2 through to Section 4.1 (12 pages). With
examples, these pages cover almost everything required to write a
recursive descent parser for any language.</p></li>

<li><p>Per
Vognsen's <a href="https://www.youtube.com/watch?v=Mx29YQ4zAuM">Programming
an x64 compiler from scratch - part 2"</a>, from 2h30m to 3h28m,
implements a simple expression parser in
C. Also, <a href="https://www.youtube.com/watch?v=0woxSWjWsb8">Bitwise,
Day 2: C Programming & Parsing</a> from 1h00m
and <a href="https://www.youtube.com/watch?v=L4P98pGhpnE">Bitwise, Day
3: More Programming & Parsing</a> from 1h10m to 1h40m are worth a
look, though they have some overlap.</p></li>

<li><p>Bob
Nystrom's <a href="http://craftinginterpreters.com/parsing-expressions.html">Crafting
Interpreters</a>, Chapter 6 details how to modify an expression
grammar to encode precedence levels.</p></li>

<li><p>Eli
Bendersky's <a href="https://eli.thegreenplace.net/2009/03/14/some-problems-of-recursive-descent-parsers">Some problems of recursive descent parsers</a> details how to transform a
right recursive grammar into repetitions and how to handle left and
right associative operators.</p></li>
</ul>

<h3>Summary</h3>

<p>Summary.</p>

</div>
