---
layout: post
title: "Recursive descent parsing of mathematical expressions with C#"
date: 2018-12-23 12:00 UTC
---

<div id="post">

<p><a href="/blog/2015/08/05/lexing-and-parsing-mathematical-expressions-with-fsharp">Part 1: Lexing and parsing mathematical expressions with F#</a><br>
<a href="/blog/2015/08/14/evaluating-mathematical-expressions-with-shunting-yard-and-fsharp">Part 2: Evaluating mathematical expressions with Shunting Yard and F#</a><br>
  Part 3: Recursive descent parsing of mathematical expressions with C#</p>

<p>The source code for this post is extensively commented and is
available
<a href="https://github.com/ronnieholm/ExpressionParsers/tree/master/RecursiveDescentParser.CSharp">here</a>.</p>
  
<p>This post is about implementing a backtracking lexer and a
recursive
descent <a href="https://en.wikipedia.org/wiki/LL_parser">LL(1)</a>
parser for mathematical expressions. The LL(1) part refers to parsing
an expression left to right, performing left-most derivations of
tokens, using a single token lookahead. For mathematical expressions,
left-most derivation implies that any operator becomes left
associative and single token lookahead implies that taking into
account the next token only, we can determine which parsing rule to
apply next. By organizing the rules by which the parser operates from
lowest to highest precedence, the parser does operator precedence
climbing to support proper operator precedence for unary -, binary +,
-, *, /, ^ operators and parenthesis.</p>

<p>The Internet is full of mathematical expression parsers because
it's the simplest non-linear parsing problem. But parsers tend to
focus on precedence only. That isn't a problem as long as we leave out
right associate operators such as unary - and binary ^. Parsing even
simple mathematical expressions, however, requires supporting both
left and right associative operators.</p>

<p>If we can create a parser for mathematical expression supporting
operators with varying precedence <i>and</i> operators with both left
and right associativity, we can reuse the patterns to parse any
language with a single token lookahead without resorting to
third-party parsing frameworks.</p>

<h3>Textbook expression grammar</h3>

<p>Below is a textbook example of a
<a href="https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form">BNF
grammar</a> for expressions. We'll evolve it into a more capable
grammar for our parser to implement. Each part of the parser can
easily be traced back to such grammar rules:</p>

<pre>
Expression = Term | Expression "+" Term | Expression "-" Term
Term = Factor | Term "*" Factor | Term "/" Factor 
Factor = Power | Factor "^" Power
Power = Integer | "(" Expression ")"
Integer = Digit | Integer Digit    
Digit = "0" | "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9" 
</pre>

<p>The <code>Integer</code> and <code>Digit</code> rules are handled
by the lexer and included for completeness sake only. The lexer
operates at the character level whereas the parser operates and the
token level, and generally handles rules expressed by a regular
language, i.e., one for which a regular expression can be
defined. When we talk about single token lookahead, we're referring to
the operation of the parser and not the lexer. The lexer may look any
number of characters ahead.</p>

<p>To understand the grammar, it may help to brush up on terminology
from
<a href="https://study.com/academy/lesson/parts-of-an-expression-terms-factors-coefficients.html">algebra</a>. A
term refers to the operands part of an expression involving addition
or subtraction operators. A factor refers to the operands part of an
expression involving multiplication or division operators.</p>

<h3>Adjusting grammar for off-by-one naming</h3>

<p>Looking at the textbook expression grammar, the rules appear
off-by-one: the <code>Expression</code> rule is about addition and
subtraction, the <code>Term</code> rule about multiplication and
division, and so on. If instead, we rewrite, or expand, the first rule
into two, we end up with the grammar below where Terms, Factors, and
so match with their definition. Since we introduced an extra level, we
name the last rule <code>Primary</code> (and leave out lexer
rules):</p>

<pre>
Expression = Term
Term = Factor | Term "+" Factor | Term "-" Factor
Factor = Power | Factor "*" Power | Factor "/" Power
Power = Primary | Power "^" Primary
Primary = Integer | "(" Expression ")"
</pre>
 
<p>In general, a grammar <code>A = B, B = C | D</code> can be
rewritten as <code>A = B | C | D</code>. Both grammars define the same
language.</p>

<p>In principle, rule names doesn't matter. We might as well designate
rules as <code>Rule0</code>, <code>Rule1</code>,
<code>RuleN</code> with N denoting the precedence level for the rule's
operator(s). Within a grammar, and hence within recursive descent
parsers, precedence is defined by one rule referencing another in
increasing order of precedence.</p>

<p>Because in the grammar above, the rule's self-reference appears on
the left, as in
<code>Term = Term "+" Factor</code>, the rule is left recursive and
parses left associative operators, e.g., <code>a - b - c parses as (a
- b) - c</code>. Right associative operators would require making the
rule right recursive as in <code>Primary "^"
Power</code>. Unfortunately, recursive descent parsers cannot work
with left recursion. In order to parse <code>Term = Term "+"
Factor</code>, it would recurse into itself, leading to an infinite
loop.</p>

<h3>Eliminating left recursion with EBNF rule rewriting</h3>

<p>That's where
<a href="https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form">EBNF</a>
comes in. Instead of left recursion, <code>{ x }</code> syntax is
introduced to express zero or more repetitions, expressed with a loop
rather than recursion.</p>

<p><b>Side note</b>: a recursive descent parser has no issue with
right recursive rules. So instead of substituting left recursive with
iterations, an alternative is to rewrite the grammar to become all
right recursive. A transformation may then be applied on the
constructed <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract
Syntax Tree</a> (AST) node for left associative operators. While it
would work, it's overly complex compared to rewriting to
iterations:</p>

<pre>
Expression = Term
Term = Factor { ("+" | "-") Factor }
Factor = Power { ("*" | "/")  Power }
Power = Primary { "^" Primary }
Primary = Integer | "(" Expression ")"
</pre>
    
<p>Favoring readability over compactness, and extending the grammar to
include unary minus and float support, we end up with this final
grammar:</p>

<pre>
Expression = Addition
Addition = Multiplication { ("+" | "-") Multiplication }
Multiplication = Power { ("*"|"/") Power }
Power = Unary { "^" Power }
Unary = '-' Unary | Primary
Primary = Integer | Float | "(" Expression ")"
</pre>

<p>Naming
rules <code>Addition</code>, <code>Multiplication</code>, <code>Power</code>
is short for operators with addition, multiplication, and power-like
precedence.</p>

<p><b>Side node</b>: lots of languages are LL(1) at the token level
but not the character level. In fact, one reason to separate the lexer
and parser is to allow the parser to be LL(1). For instance, prior to
lexing a integer or float, the lexer bookmarks its current
position. It then scans the input until it encounters either a
whitespace or a dot, before it backtracks to the bookmark and calls
the appropriate integer or float lexer method.</p>

<h3>From grammar rules to parser</h3>

<p>Organizing the parser, each rule becomes a corresponding Parse
method. Placing a breakpoint inside one of these methods, the call
stack shows the path from <code>Expression</code> to the current
rule. This is useful in debugging the parser and goes to show the
one-to-one relationship between grammar and recursive descent
parser.</p>

<p>To keep the code simple,
the <a href="https://github.com/ronnieholm/ExpressionParsers/tree/master/RecursiveDescentParser.CSharp">implementation</a>,
evaluates expressions during parsing. We might also have returned AST
nodes from each parse method as with
the <a href="https://github.com/ronnieholm/ExpressionParsers/tree/master/ShuntingYardParser.CSharp">Shunting
Yard implementation</a> and add an AST tree walking interpreter. Both
solutions work because the evaluation order is correct with respect to
associativity and precedence.</p>

<p>Below is the trace output from parsing an expression. The trace
reflects the parser's call stack with each Enter marking an entry into
a parse method, 20 in all, and the value of the current token. Exit
marks includes what each parse method returns up the call chain to its
caller.</p>

<pre>
// Equivalent to 2+(3^(4^0.5)*5)
> 2+3^4^0.5*5
Enter: Parse, Value: 2
    Enter: ParseExpression, Value: 2
        Enter: ParseAddition, Value: 2
            Enter: ParseMultiplication, Value: 2
                Enter: ParsePower, Value: 2
                    Enter: ParseUnary, Value: 2
                        Enter: ParsePrimary, Value: 2
                        Exit: Value: 2
                    Exit: Value: 2
                Exit: Value: 2
            Exit: Value: 2
            Enter: ParseMultiplication, Value: 3
                Enter: ParsePower, Value: 3
                    Enter: ParseUnary, Value: 3
                        Enter: ParsePrimary, Value: 3
                        Exit: Value: 3
                    Exit: Value: 3
                    Enter: ParsePower, Value: 4
                        Enter: ParseUnary, Value: 4
                            Enter: ParsePrimary, Value: 4
                            Exit: Value: 4
                        Exit: Value: 4
                        Enter: ParsePower, Value: 0.5
                            Enter: ParseUnary, Value: 0.5
                                Enter: ParsePrimary, Value: 0.5
                                Exit: Value: 0.5
                            Exit: Value: 0.5
                        Exit: Value: 0.5
                    Exit: Value: 2
                Exit: Value: 9
                Enter: ParsePower, Value: 5
                    Enter: ParseUnary, Value: 5
                        Enter: ParsePrimary, Value: 5
                        Exit: Value: 5
                    Exit: Value: 5
                Exit: Value: 5
            Exit: Value: 45
        Exit: Value: 47
    Exit: Value: 47
Exit: Value: 47
</pre>

<p>Because the parser and the grammar rules map one-to-one, following
the grammar rules by hand, we'd arrive at the same order. Constructing
a parser from a grammar rules is a large mechanical process.</p>

<h3>Comparison of recursive descent, Shunting Yard, and Pratt parsers</h3>

<p>The recursive descent approach to parsing is probably the easiest
and most intuitive of all. It's been known at least since the 60s, but
was impractical to implement. At that time, the idea of a call stack
was novel, function calls slow, and memory for the stack scarce. The
Shunting Yard algorithm was invented to overcome these limitations. On
modern computers, method calls are fast and memory cheap. So unless
we're parsing large programs with many precedence levels, recursive
descent is a good starting point.</p>

<p>In 1973, the <a href="https://tdop.github.io">Pratt parser</a>, or
Top Down Operator Precedence parser, was introduced. It was an
improvement on Shunting Yard in that a Pratt parser requires only a
single parse method call regardless of precedence level, making it
efficient for grammars with many levels of precedence. It's also
useful in language with the ability to add new operators at any
position in the precedence hierarchy and with any associativity. A
recursive descent parsers is fixed unless we replace of supplement
existing rules with a dynamic lookup table or parse methods to
call.</p>

<p>For an example of a hybrid of a recursive descent parser for
statements and a Pratt parser for expressions, take a look
at <a href="https://github.com/ronnieholm/MonkeyLang">MonkeyLang</a>.</p>

<h3>Additional references</h3>

<ul>
<li><p>Niklaus
Wirth's <a href="https://www.inf.ethz.ch/personal/wirth/CompilerConstruction/CompilerConstruction1.pdf">Compiler
construction</a>, Chapter 2 through to Section 4.1 (12 pages). With
examples, these pages cover almost everything required to write a
recursive descent parser for any language.</p></li>

<li><p>Per
Vognsen's <a href="https://www.youtube.com/watch?v=Mx29YQ4zAuM">Programming
an x64 compiler from scratch - part 2"</a>, offsets 2h30m to 3h28m,
implements a simple expression parser in C. Also, <a href="https://www.youtube.com/watch?v=0woxSWjWsb8">Bitwise,
Day 2: C Programming & Parsing</a>
and <a href="https://www.youtube.com/watch?v=L4P98pGhpnE">Bitwise, Day
3: More Programming & Parsing</a> are worth a look, though they have
some overlap.</p></li>

<li><p>Bob
Nystrom's <a href="http://craftinginterpreters.com/parsing-expressions.html">Crafting
Interpreters</a>, Chapter 6 details how to modify an expression
grammar to encode precedence levels.</p></li>

<li><p>Eli
Bendersky's <a href="https://eli.thegreenplace.net/2009/03/14/some-problems-of-recursive-descent-parsers">Some problems of recursive descent parsers</a> details how to transform a
right recursive grammar into repetitions and how to handle left and
right associative operators.</p></li>
</ul>

<h3>Summary</h3>

<p>Summary.</p>

</div>
