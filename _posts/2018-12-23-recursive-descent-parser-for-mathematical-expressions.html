---
layout: post
title: "Recursive descent parsing of mathematical expressions with C#"
date: 2018-12-23 12:00 UTC
---

<!--
See ParsePower() for how to reverse associativity from default left to right on a per-operator basis.
-->

<div id="post">

<p><a href="/blog/2015/08/05/lexing-and-parsing-mathematical-expressions-with-fsharp">Part1: Lexing and parsing mathematical expressions with F#</a><br>
<a href="/blog/2015/08/14/evaluating-mathematical-expressions-using-shunting-yard-and-fsharp">Part 2: Evaluating mathematical expressions using Shunting Yard and F#</a><br>
  Part 3: Recursive descent parsing of mathematical expressions with C#</p>

<p>The source code for this post is extensively commented and is
available
<a href="https://github.com/ronnieholm/ExpressionParsers/tree/master/RecursiveDescentParser.CSharp">here</a>.</p>
  
<p>This post is about implementing a backtracking lexer and a
recursive
descent <a href="https://en.wikipedia.org/wiki/LL_parser">LL(1)</a>
parser for mathematical expressions. The LL(1) part refers to parsing
an expression left to right, performing left-most derivations of
tokens, using a single token lookahead. For mathematical expressions,
left-most derivation implies that any operator becomes left
associative and single token lookahead implies that taking into
account the next token only, we can determine which parsing rule to
apply next. By organizing the rules by which the parser operates from
lowest to highest precedence, the parser does operator precedence
climbing to support proper operator precedence for unary -, binary +,
-, *, /, ^ operators and parenthesis.</p>

<p>The Internet is full of mathematical expression parsers because
it's the simplest non-linear parsing problem. But parsers tend to
focus on precedence only. That isn't a problem as long as we leave out
right associate operators such as unary - and binary ^. Parsing even
simple mathematical expressions, however, requires supporting both
left and right associative operators.</p>

<p>If we can create a parser for mathematical expression supporting
operators with varying precedence <i>and</i> operators with both left
and right associativity, we can reuse the patterns to parse any
language with a single token lookahead without resorting to
third-party parsing frameworks.</p>

<h3>Textbook expression grammar</h3>

<p>Below is a textbook example of a
<a href="https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form">BNF
grammar</a> for expressions. We'll evolve it into a more capable
grammar for our parser to implement. Each part of the parser can
easily be traced back to such grammar rules:</p>

<pre>
// Parser rules
Expression = Term | Expression "+" Term | Expression "-" Term
Term = Factor | Term "*" Factor | Term "/" Factor 
Factor = Power | Factor "^" Power
Power = Integer | "(" Expression ")"

// Lexer rules
Integer = Digit | Integer Digit    
Digit = "0" | "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9" 
</pre>

<p>The <code>Integer</code> and <code>Digit</code> rules are handled
by the lexer and included for completeness sake only. The lexer
operates at the character level whereas the parser operates and the
token level, and generally handles rules expressed by a regular
language, i.e., one for which a regular expression can be
defined. When we talk about single token lookahead, we're referring to
the operation of the parser and not the lexer. The lexer may look any
number of characters ahead.</p>

<p>To understand the grammar, it may help to brush up on terminology
from
<a href="https://study.com/academy/lesson/parts-of-an-expression-terms-factors-coefficients.html">algebra</a>. A
term refers to the operands part of an expression involving addition
or subtraction operators. A factor refers to the operands part of an
expression involving multiplication or division operators.</p>

<h3>Adjusting the grammar for off-by-one</h3>

<p>Looking at the textbook expression grammar, the rules appear
off-by-one: the <code>Expression</code> rule is about addition and
subtraction, the <code>Term</code> rule about multiplication and
division, and so on. If instead, we rewrite, or expand, the first rule
into two, we end up with the grammar below where Terms, Factors, and
so match with their definition. Since we introduced an extra level, we
name the last rule <code>Primary</code> (and leave out lexer
rules):</p>

<pre>
Expression = Term
Term = Factor | Term "+" Factor | Term "-" Factor
Factor = Power | Factor "*" Power | Factor "/" Power
Power = Primary | Power "^" Primary
Primary = Integer | "(" Expression ")"
</pre>
 
<p>In general, a grammar <code>A = B, B = C | D</code> can be
rewritten as <code>A = B | C | D</code>. Both grammars define the same
language.</p>

<p>In principle, rule names doesn't matter. We might as well designate
rules as <code>Rule0</code>, <code>Rule1</code>,
<code>RuleN</code> with N denoting the precedence level for the rule's
operator(s). Within a grammar, and hence within recursive descent
parsers, precedence is defined by one rule referencing another in
increasing order of precedence.</p>

<p>Because in the grammar above, the rule's self-reference appears on
the left, as in
<code>Term = Term "+" Factor</code>, the rule is left recursive and
parses left associative operators, e.g., <code>a - b - c parses as (a
- b) - c</code>. Right associative operators would require making the
rule right recursive as in <code>Primary "^"
Power</code>. Unfortunately, recursive descent parsers cannot work
with left recursion. In order to parse <code>Term = Term "+"
Factor</code>, it would recurse into itself, leading to an infinite
loop.</p>

<h3>Eliminating left recursion with EBNF rule rewriting</h3>

<p>That's where
<a href="https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form">EBNF</a>
comes in. Instead of left recursion, <code>{ x }</code> syntax is
introduced to express zero or more repetitions, naturally expressed
with a loop rather than infinite recursion.</p>

<p><b>Side note</b>: a recursive descent parser has no issue with
right recursive rules. So instead of substituting left recursive with
iterations, an alternative is to rewrite the grammar to become all
right recursive. A transformation may then be applied on the
constructed <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract
Syntax Tree</a> (AST) node for left associative operators. While it
would work, it's overly complex compared to rewriting to
iterations:</p>

<pre>
Expression = Term
Term = Factor | { "+" Factor } | { "-" Factor }
Factor = Power | { "*" Power } | { "/" Power }
Power = Primary | { "^" Primary }
Primary = Integer | "(" Expression ")"
</pre>
    
<p>Favoring readability over compactness, and extending the grammar
with unary minus and float support, we end up with this final
grammar:</p>

<pre>
// Parser rules
Expression = Addition
Addition = Multiplication | { "+" Multiplication } | { "-" Multiplication }
Multiplication = Power | { "*" Power } | { "/" Power }    
Power = Unary | { "^" Power }
Unary = '-' Unary | Primary
Primary = Integer | Float | "(" Expression ")"

// Lexer rules
Float = Integer "." Integer
Integer = Digit | { Digit }
Digit = "0" | "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9"    
</pre>

<p>When we name a
rule <code>Addition</code>, <code>Multiplication</code>, <code>Power</code>
it's short for operators with addition, multiplication, and power-like
precedence.</p>

<!--
                    // Once we know whether we're at a float or an integer,
                    // we'll backtrack using the bookmark and call the
                    // appropriate lexer method. Note that LL(1) refers to one
                    // token lookahead at the parser level, not the lexer. A lot
                    // of languages that are LL(1) at the token level aren't
                    // LL(1) at the character level. One reason to separate the
                    // lexer and parser is to allow the parser to be LL(1).
  -->

<h3>From grammar rules to parser</h3>

<p>Inside the parser, each rule is matched by a corresponding Parse
method. Placing a breakpoint inside one of these methods, the call
stack shows the path from <code>Expression</code> to the current
rule. This is useful in debugging the parser and illustrates the
one-to-one relationship between a grammar and a recursive descent
parser.</p>

<p><b>Side note</b>: using additional EBNF syntax and the Kleene star,
the grammar could be further simplified, but we'll forgo that
part.</p>

<p>In the example parser, we evaluate the expression as we parse it.
We might also have returned AST nodes from each parse method as with
the Shunting Yard example. We know that the evaluation order is
correct with respect to associativity and precedence, so the AST would
be correct intermediate representation. Writing an evaluator for the
AST, the interpreter would no longer be one-pass but two-pass.</p>

<h3>Comparison of recursive descent, Shunting Yard, and Pratt parsers</h3>

<p>The recursive descent approach to parsing is probably the easiest
and most intuitive way of parsing a program. The translation from
grammar to parser straightforward. It's just that in the 60s, it was
impractical to implement because the idea of the call stack was new,
function calls slow, and memory scarce. Shunting Yard was invented to
overcome these limitations. Instead of recursion, Shunting Yard loops
over an operator stack, consulting lookup tables of operator
precedence and associativity, while reading operands from the operand
stack.</p>

<p>In 1973, the <a href="https://tdop.github.io">Pratt parser</a>,
also called Top Down Operator Precedence parser, was presented. It
remained largely unknown till around 2005. Regardless of an operator's
precedence level, the Pratt parser always requires only a single
lookup to process the operator, making it efficient for grammars with
many levels of precedence. It also has the ability to dynamically, at
runtime, adding new operators at any position in the
hierarchy. Recursive descent is fixed, although image a recursive
descent parser that dynamically looks up the next method to call from
a table, and it would have the same dynamic ability as the Pratt
parser.</p>

<p>For an example of a hybrid of a traditional recursive descent
parser for statements and a Pratt parser for expressions, take a look
at <a href="https://github.com/ronnieholm/MonkeyLang">MonkeyLang</a>.</p>

<h3>Additional references</h3>

<ul>
<li><p>Niklaus
Wirth's <a href="https://www.inf.ethz.ch/personal/wirth/CompilerConstruction/CompilerConstruction1.pdf">Compiler
construction</a>, Chapter 2 through to Section 4.1 (12 pages). With
examples, these pages cover almost everything required to write a
recursive descent parser for any language.</p></li>

<li><p>Per
Vognsen's <a href="https://www.youtube.com/watch?v=Mx29YQ4zAuM">Programming
an x64 compiler from scratch - part 2"</a>, offsets 2h30m to 3h28m,
implements a simple expression parser in
C. Also, <a href="https://www.youtube.com/watch?v=0woxSWjWsb8">Bitwise,
Day 2: C Programming & Parsing</a>
and <a href="https://www.youtube.com/watch?v=L4P98pGhpnE">Bitwise, Day
3: More Programming & Parsing</a> are worth a look, though they have
some overlap.</p></li>

<li><p>Bob
Nystrom's <a href="http://craftinginterpreters.com/parsing-expressions.html">Crafting
Interpreters</a>, Chapter 6 details how to modify an expression
grammar to encode precedence levels.</p></li>

<li><p>Eli
Bendersky's <a href="https://eli.thegreenplace.net/2009/03/14/some-problems-of-recursive-descent-parsers">Some
problems of recursive descent parsers</a> details how to transform a
right recursive grammar into repetitions and how to handle left and
right associative operators.</p></li>
</ul>

<h3>Summary</h3>

<p>Summary.</p>

</div>
